mddir Equity
    
   65  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/ -06A .txt -r - --o-parent -nd â-w 2 --limit-rate=20k  //where I found some hidden chars :p
   66  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/ 6A -A.txt -r - --oarent -nd â-w 2 --limit-rate=20k
   67* wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/ 6A -A.txt -r - -
   68  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/ -06A .txt -r --o-parent -nd âw 2 --limit-rate=20k
   69  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883//06 -A .txt -l 1  -r --no-parent -nd -w 2 --limit-rate=50k
   70  ls
   71  cd E*
   72  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883//06 -A .txt -l 1  -r --no-parent -nd -w 2 --limit-rate=50k  /just trying different combinations to see if I could just grab one file from each directory
   73  ls
   74  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06 -A .txt -l 1  -r --no-parent -nd -w 2 --limit-rate=50k
   75  ls
   76  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -A .txt -l 1  -r --no-parent -nd -w 2 --limit-rate=50k
   77  ls
   78  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -A .txt -l 2  --no-parent -nd -w 2 --limit-rate=50k
   79  ls
   80  rm index*
   81  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -A .txt -l 2 -r  --no-parent -nd -w 2 --limit-rate=50k
   82  ls
   83  rm *.txt
   84  ls
   85  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/*/ -A .txt -l 2   --no-parent -nd -w 2 --limit-rate=50k
   86  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -A .txt -l 2   --no-parent -nd -w 2 --limit-rate=50k
   87  ls
   88  rm index*
   89  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -A "*".txt -l 2   --no-parent -nd -w 2 --limit-rate=50k
   90  rm index*
   91  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -A "*".txt -l 2   --no-parent -nc -nd -w 2 --limit-rate=50k
   92  ls
   93  rm ind*
   94  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -A "*".txt -l 1   --no-parent -nc -nd -w 2 --limit-rate=50k
   95  ls
   96  nano inde*
   97  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -A "*".txt -l 1   --no-parent  -nd -w 2 --limit-rate=50k   //this gets the index.html always
   98  ls
   99  rm ind*
  100  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ --reject html -A "*".txt -l 1   --no-parent  -nd -w 2 --limit-rate=50k //still gets index html
  101  ls
  102  rm ind*
  103  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ --reject "index.html" -A "*".txt -l 1   --no-parent  -nd -w 2 --limit-rate=50k
  104  ls
  105  rm ind*
  106  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -r  -A "*".txt -l 1   --no-parent  -nd -w 2 --limit-rate=50k
  107  ls
  108  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/   -A .txt -l 2 --no-parent  -nd -w 2 --limit-rate=50k
  109  ls
  110  rm *.html
  111  ls
  112  rm in*
  113  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/  -p  -A .txt -l 2 --no-parent  -nd -w 2 --limit-rate=50k
  114  ls
  115  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/  -P  -A .txt -l 2 --no-parent  -nd -w 2 --limit-rate=50k
  116  ls
  117  dir -A
  118  ls
  119  cd ..
  120  rm -A
  121  rmdir *A
  122  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/  -Q 1  -A .txt -l 2 --no-parent  -nd -w 2 --limit-rate=50k
  123  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/  -Q 2  -A .txt -l 2 --no-parent  -nd -w 2 --limit-rate=50k
  124  ls
  125  cd Eq*
  126  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/  -Q 2  -A .txt -l 2 --no-parent  -nd -w 2 --limit-rate=50k
  127  ls
  128  rm ind*
  129  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/07    -A .txt -l 2 --no-parent  -nd -w 2 --limit-rate=50k
  130  ls
  131  rm 07
  132  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/07 -r -A .txt -l 2 --no-parent  -nd -w 2 --limit-rate=50k
  133  ls
  134  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/07 -r -R index,html -A .txt -l 2 --no-parent  -nd -w 2 --limit-rate=50k
  135  ls
  136  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/07 -r -R html -A .txt -l 2 --no-parent  -nd -w 2 --limit-rate=50k
  137  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -r -R html -A .txt -l 1 --no-parent  -nd -w 2 --limit-rate=50k
  138  ls
  139  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -r -R html  -A .txt -l 1 --no-parent  -nd -w 2 --limit-rate=50k -O >test.txt  //was hoping if I wrote the output to a file it would ignor index
  140  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/06/ -r -R html  -A .txt -l 1 --no-parent  -nd -w 2 --limit-rate=50k -O test.txt
  141  ls
  142  nano test.txt
  143  rm test*
  144  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/188*/*/0*/ -r -R html  -A .txt -l 1 --no-parent  -nd -w 2 --limit-rate=50k -O test.txt
  145  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/ -r -R html  -A "-0*".txt -l 2 --no-parent  -nd -w 2 --limit-rate=50k    //trying to see if I could grab just files ending with a day that starts with zero 
  146  ls
  147* wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/  -A 
  148  ls
  149  cd co*
  150  ls
  151  cd jrn03*
  152  ls
  153  cd e*
  154  cd *
  155  ls
  156  cd *
  157  ls
  158  cd *
  159  ls
  160  cd *
  161  ls
  162  cd ~
  163  ls
  164  cd E*
  165  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/ -r -R html  -A "-0*".txt  --no-parent  -nd -w 2 --limit-rate=50k -nH --cut-dirs=3  
  166  ls
  167  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/ -r  -A "*-0?".txt  --no-parent  -nd -w 2 --limit-rate=50k -nH --cut-dirs=3  //want to trim directorys down and wild card works for one char now aka: '?'
  168  ls
  169  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/   -A "*-0?".txt  --no-parent  -nd -w 2 --limit-rate=50k -nH 
  170  ls
  171  rm ind*
  172  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/  -r  -A "*-0?".txt  --no-parent  -nd -w 2 --limit-rate=50k -nH 
  173  ls
  174  rm *.txt
  175  ls
  176  wget http://collections.banq.qc.ca:8008/jrn03/equity/src/1883/ -r  -A "*-0?".txt  --no-parent   -w 2 --limit-rate=50k -nH --cut-dirs=3  //at this test decided directory not needed and started writing a script to itterate though a bunch of days
  177  ls
  178  cd 1883
  179  ls
  180  cd ..
  181  ls
  182  nano script.sh
  183  ps
  184  kill -9 17860
  185  ps
  186  ls
  187  nano script.sh
  188  ps
  189  kill -9 17876
  190  nano script.sh
  191  ls
  192  script.sh
  193  ls
  194  script
  195  kill 17886
  196  kill 17908
  197  ps
  198  ps -a
  199  ./script.sh   /ran the script, looking back I probaly could of got the same results running from the /src directory but to late now
  200  ls
  201  zip
  202  zip -r textfiles.zip ./  /zipped the folders for downloading to windows with ease :D
  203  ls
  204  history
  205  cd ..
  206  history > 2017-08-13.txt
  uploaded all the files downloaded to open refine to start cleaning up the data. This took a while as it was 1017 files
Forgot to remove the months that had more than 1 week in the files
After removing the extra files there is now only 848 files, also noticed while going through the files that a lot of months near the begining are missing altogether, check the shawville site and found the same thing
Upload the files to open refine
Since I did not clean up the files before, I had to select how to parse the data
Choose line based text option
Decided to change what topics I was looking for. Changing it topics realted to Different contries. Marking the lines that have one of the below contries on it and then removing the rest of the information in the docks

sudo find *.txt -type f -exec sed -i.bak "s/(.+\b(Canada|England|Britan|France|Germany|Holland|USA|United States|Italy|Poland|Spain|Russia|Soviet Union|Japan|Korea)\b.+)/~\1/ig" {} \; - this threw an error, saying it didn't like \1

sudo find *.txt -type f -exec sed -r -i.bak "s/(.+\b(Canada|England|Britan|France|Germany|Holland|USA|United States|Italy|Poland|Spain|Russia|Soviet Union|Japan|Korea)\b.+)/~\1/ig" {} \;  -forgot the -r
grep '~' HistoryFiles/*.txt > importantText.txt
sed -r -i.bak 's/~//g' impo*.txt
sed -r -i.bak 's/HistoryFiles\/83471\_([0-9]{4})\-([0-9]{2})\-([0-9]{2}).txt\:/\1,\2/gi' import*.txt -- decided that just having the years would be better
mv impor*.txt.bak import*.txt -- replaced with backup
sed -r -i.bak 's/HistoryFiles\/83471\_([0-9]{4})\-([0-9]{2})\-([0-9]{2}).txt\:/\1\: /gi' import*.txt --
cleaned up the text and put all the contries of intrest after the year
  101  sed -r -i.bak 's/~//gi' impo*.txt
  102  nano im*
  103  sed -r -i.bak 's/ */ /gi' impo*.txt
  104  nano im*
  105  mv impor*.txt.bak import*.txt
  106  nano im*.txt
  107  sed -r -i.bak 's/\t//gi' impo*.txt
  108  nano im*.txt
  109  sed -r -i.bak 's/[,.;]//gi' impo*.txt
  110  nano im*.txt
  111  sed -r -i.bak 's/[\^!]//gi' impo*.txt
  112  nano im*.txt
  113  mv impor*.txt.bak import*.txt
  114  sed -r -i.bak 's/ /,/gi' impo*.txt
  115  nano im*.txt
  116  sed -r -i.bak 's/([0-9]{4}:)(,)/\1 /gi' impo*.txt
  117  nano im*.txt
  118  sed -r -i.bak 's/([0-9]{4}:)( ,)/\1 /gi' impo*.txt
  119  nano im*.txt
  120  sed -i.bak 's/([0-9]{4}\: )(.*)(Canada|England|Britan|France|Germany|Holland|USA|United States|Italy|Poland|Spain|Russia|Soviet Union|Japan|Korea)(.*)/\1\3\:\2\4/gi' impor*.txt
  121  sed -r -i.bak 's/([0-9]{4}\: )(.*)(Canada|England|Britan|France|Germany|Holland|USA|United States|Italy|Poland|Spain|Russia|Soviet Union|Japan|Korea)(.*)/\1\3\:\2\4/gi' impor*.txt
after playing around with line 121, it should wrok for all cases. However, even with check it exc and trying slight changes here and there it still does work of every case. Not sure why as it works fine for so many...

benvanstarkenburg@33ae2074d9c3:~$ sudo find *.txt -type f -exec sed -r -i.bak "s/(.+\b(United,States)\b.+)/~\1/ig" {} \;
benvanstarkenburg@33ae2074d9c3:~$ nano im*.txt
benvanstarkenburg@33ae2074d9c3:~$ mv impor*.txt.bak import*.txt
benvanstarkenburg@33ae2074d9c3:~$ sudo find *.txt -type f -exec sed -r -i.bak "s/([0-9]{4}\: )(.*)(United,States)(.*)/\1\3\:\2\4/gi" {} \; --made a mistake with that so added it back in
unknown chars were causing issues so I removed anything up to the character whenever possible
cleaned up the data a bit using open refine, just apllied the basic text clean up and split the document
brought the data back to rstudio



---------------------------------------------------------------------------------------------------------------------------------------- took way to long to get it to count the frequency of the words the first time
install.packages("mallet")
library("mallet")
documents <- mallet.read.dir("~/finalProject")
mallet.instances <- mallet.import(documents$id, documents$text, "en.txt", token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")
mallet.instances <- mallet.import(documents$id, documents$text, "~/finalProject/en.txt", token.regexp = "\\p{L}[\\p{L}\\p{P}]+\\p{L}")
num.topics <- 20
topic.model <- MalletLDA(num.topics)
topic.model$loadDocuments(mallet.instances)
vocabulary <- topic.model$getVocabulary()
word.freqs <- mallet.word.freqs(topic.model)
head(word.freqs)
write.csv(word.freqs, "word-freqs.csv" )
added some more lines from the originaly provided en.txt as men time year people and tho had high occurences
brought data back to open refine and cleaned up the rows removing a couple thousand lines
removed all rows but the top 800 results
